{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df0d9a0",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeff4f3",
   "metadata": {},
   "source": [
    "- **torch.from_numpy(ndarray)**    - NumPy array     -->  PyTorch tensor.\n",
    "- **torch.Tensor.numpy()**         - PyTorch tensor  -->  NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6583912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array -> PyTorch tensor \n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 10.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cdec06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype , tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2d67b",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "نوع داده پیش فرض در NumPy از نوع float43 هست\n",
    "\n",
    "وقتی از NumPy به PyTorch تبدیل میکنیم ، نوع داده از متغیر مبدا کپی میشه\n",
    "    \n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7ccd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.from_numpy(array).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4aea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9be5cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = array + 2\n",
    "array , tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1659e114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array -> PyTorch tensor\n",
    "tensor = torch.zeros(8)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor , numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b727e7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, dtype('float32'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype , numpy_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a54ef09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 1\n",
    "tensor , numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311d65e",
   "metadata": {},
   "source": [
    "### Reproducibility \n",
    "\n",
    "تکرار الگوهای تصادفی\n",
    "\n",
    "در طول این دوره به اهمیت تولید اعداد تصادفی در ساخت و استفاده از شبکه های عصبی و یادگیری ماشین بیشتر پی میبریم\n",
    "\n",
    "بیشتر مدلهای شبکه های عصبی و هوش مصنوعی به طور کلی از روند زیر پیروی میکنند:\n",
    "\n",
    "1. با اعداد تصادفی شروع کن\n",
    "2. محاسبات مورد نظر رو انجام بده\n",
    "3. نتایج رو بهتر کن\n",
    "4. همین روند رو تکرار کن\n",
    "\n",
    "\n",
    "با اینکه تولید اعداد تصادفی مهم و حیاتی هستند برای این پروسه ، گاهی ما نیاز داریم (برای آزمایش یا تکرار نتایج و بررسی) همون اعداد رو تولید کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "023200ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.3906, 0.6538, 0.6440, 0.8795],\n",
      "        [0.6813, 0.9011, 0.4105, 0.3022],\n",
      "        [0.3226, 0.4308, 0.6492, 0.8568]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.4829, 0.5384, 0.8557, 0.2473],\n",
      "        [0.2483, 0.4148, 0.4512, 0.1732],\n",
      "        [0.0494, 0.2218, 0.4972, 0.8161]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf93a9",
   "metadata": {},
   "source": [
    "### Random Seed\n",
    "\n",
    "Wikipedia: https://en.wikipedia.org/wiki/Random_seed\n",
    "\n",
    "PyTorch Docs: https://pytorch.org/docs/stable/notes/randomness.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f940eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# # Set the random seed\n",
    "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f81ad",
   "metadata": {},
   "source": [
    "# Tensors on GPUs\n",
    "\n",
    "\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "    \n",
    "CPU یا Central Processing Unit (واحد پردازش مرکزی)، یک قطعه سخت‌افزاری است که مسئول اجرای برنامه‌ها و دستورات سیستمی در یک سیستم کامپیوتری است. CPU در عملیات‌های متناوب، محاسباتی سنگین و کاربردهای گسترده دیگر به کار می‌رود. به طور کلی، CPU مجهز به تعداد کمی هسته پردازشی (معمولاً ۲ تا ۱۶ هسته) است، هر کدام با سرعت بالایی اجرا می‌شوند، با توجه به فرکانس ساعت (clock speed) آن‌ها.\n",
    "\n",
    "اما GPU یا Graphics Processing Unit (واحد پردازش گرافیکی) برای کاربردهای گرافیکی به کار می‌رود، مثل بازی‌های ویدیویی، ویرایش ویدیو و عکس و محاسبات علمی. GPU با تعداد زیادی هسته پردازشی (معمولاً بیشتر از ۱۰۰۰ هسته) و فرکانس ساعت پایین‌تر از CPU، برای انجام محاسبات گرافیکی و محاسبات ماتریسی بسیار سریع است.\n",
    "\n",
    "به طور کلی، CPU برای محاسبات عمومی و سنگین، مانند محاسبات شبکه‌های عصبی و پردازش صوتی و متنی مناسب است. از سوی دیگر، GPU برای محاسبات گرافیکی و علمی، مانند محاسبات شبیه‌سازی فیزیکی، یادگیری ژرف و شبکه‌های عصبی عظیم الجثه، مناسب است.\n",
    "\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc448552",
   "metadata": {},
   "source": [
    "### Getting a GPU\n",
    "\n",
    "\n",
    "| **روش** | **راه اندازی** | **مزایا** | **معایب** | **راهنما** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Google Colab | Easy | Free to use, almost zero setup required, can share work with others as easy as a link | Doesn't save your data outputs, limited compute, subject to timeouts | [Follow the Google Colab Guide](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
    "| Use your own | Medium | Run everything locally on your own machine | GPUs aren't free, require upfront cost | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/locally/) |\n",
    "| Cloud computing (AWS, GCP, Azure) | Medium-Hard | Small upfront cost, access to almost infinite compute | Can get expensive if running continually, takes some time ot setup right | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/cloud-partners/) |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39370f",
   "metadata": {},
   "source": [
    "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means \"run this on the command line\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22d518e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 19 23:24:28 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.04              Driver Version: 531.29       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti      On | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   34C    P8               32W / 370W|   1368MiB / 12288MiB |     11%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       224      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50a80e",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "اگر `GPU` ندارید یا درایور نصب نباشه پیغامی شبیه به این ممکنه بگیرید:\n",
    " \n",
    "</div>\n",
    "\n",
    "`\n",
    "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ba3fd",
   "metadata": {},
   "source": [
    "### PyTorch on GPU\n",
    "\n",
    "#### TORCH.CUDA\n",
    "##### This package adds support for CUDA tensor types, that implement the same function as CPU tensors, but they utilize GPUs for computation.\n",
    "\n",
    "It is lazily initialized, so you can always import it, and use is_available() to determine if your system supports `CUDA`.\n",
    "\n",
    "`CUDA` semantics has more details about working with `CUDA`.\n",
    "\n",
    "https://pytorch.org/docs/stable/cuda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7dd214",
   "metadata": {},
   "source": [
    "#### Check GPU / CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26937c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4bf277",
   "metadata": {},
   "source": [
    "#### Set device to CUDA / GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77e8e859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaada94",
   "metadata": {},
   "source": [
    "#### Multi GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57f38400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi GPU\n",
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56856a",
   "metadata": {},
   "source": [
    "#### Putting tensors (and models) on the GPU\n",
    "\n",
    "`.to(device)` return a `COPY` of tensor on the other deive, thus tensor will be on both `CPU` and `GPU`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "229f85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2267a5ad",
   "metadata": {},
   "source": [
    "#### Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f1d450c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2b18736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2f7c1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79befe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b512923",
   "metadata": {},
   "source": [
    "***تمرین ها: [لینک به فایل تمرین ها](Ex%2001%20-%20تمرینات.ipynb)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c7f6b8",
   "metadata": {},
   "source": [
    "\n",
    "**Intro:** https://pytorch.org/tutorials/beginner/basics/intro.html\n",
    "\n",
    "**Quick Start:** https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "**Tensors:** https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2e486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594b372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
